c:\Users\hasee\miniconda3\envs\segformer\Lib\site-packages\transformers\models\vit\modeling_vit.py:253: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  context_layer = torch.nn.functional.scaled_dot_product_attention(
Epoch 0 Train Loss 0.5203703046554914





























Epoch 0 Val Loss 0.2478: 100%|██████████| 241/241 [00:58<00:00,  4.14it/s]
Epoch 1 Train Loss 0.30616666589025515








































Epoch 1 Val Loss 0.2180: 100%|██████████| 241/241 [01:20<00:00,  2.99it/s]
Epoch 2 Train Loss 0.26682830618830045




















































